{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787f84d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:23:13.234874Z",
     "iopub.status.busy": "2025-12-09T08:23:13.234643Z",
     "iopub.status.idle": "2025-12-09T08:23:26.980890Z",
     "shell.execute_reply": "2025-12-09T08:23:26.979968Z"
    },
    "papermill": {
     "duration": 13.752752,
     "end_time": "2025-12-09T08:23:26.982541",
     "exception": false,
     "start_time": "2025-12-09T08:23:13.229789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping cupy as it is not installed.\n",
      "WARNING: Skipping cupy-cuda11x as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: cupy-cuda12x 13.6.0\n",
      "Uninstalling cupy-cuda12x-13.6.0:\n",
      "  Successfully uninstalled cupy-cuda12x-13.6.0\n",
      "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Collecting scipy<1.13\n",
      "  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.4/60.4 kB 5.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0) (2024.2.0)\n",
      "Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.4/38.4 MB 53.5 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "Successfully installed scipy-1.12.0\n",
      "Đã sửa xong môi trường! Bắt đầu chạy code chính...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cuml-cu12 25.2.1 requires cupy-cuda12x>=12.0.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# --- FIX LỖI MÔI TRƯỜNG KAGGLE ---\n",
    "# Lệnh này sẽ chạy trên server Kaggle để gỡ thư viện gây xung đột\n",
    "import os\n",
    "\n",
    "# Gỡ bỏ Cupy (thủ phạm chính gây xung đột với Spacy/Scipy hiện tại)\n",
    "os.system(\"pip uninstall -y cupy cupy-cuda11x cupy-cuda12x\")\n",
    "\n",
    "# Cài đặt lại Numpy và Scipy bản ổn định để tránh lỗi \"ufunc\"\n",
    "os.system(\"pip install 'numpy<2.0' 'scipy<1.13'\")\n",
    "\n",
    "# --- KẾT THÚC FIX LỖI ---\n",
    "print(\"Đã sửa xong môi trường! Bắt đầu chạy code chính...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6caa8ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:23:26.990904Z",
     "iopub.status.busy": "2025-12-09T08:23:26.990664Z",
     "iopub.status.idle": "2025-12-09T08:26:00.213936Z",
     "shell.execute_reply": "2025-12-09T08:26:00.213152Z"
    },
    "papermill": {
     "duration": 153.228729,
     "end_time": "2025-12-09T08:26:00.215242",
     "exception": false,
     "start_time": "2025-12-09T08:23:26.986513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cu124\r\n",
      "Uninstalling torch-2.6.0+cu124:\r\n",
      "  Successfully uninstalled torch-2.6.0+cu124\r\n",
      "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mFound existing installation: torchvision 0.21.0+cu124\r\n",
      "Uninstalling torchvision-0.21.0+cu124:\r\n",
      "  Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "Found existing installation: torchaudio 2.6.0+cu124\r\n",
      "Uninstalling torchaudio-2.6.0+cu124:\r\n",
      "  Successfully uninstalled torchaudio-2.6.0+cu124\r\n",
      "Collecting torch==2.3.0\r\n",
      "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting torchtext==0.18.0\r\n",
      "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\r\n",
      "Collecting torchvision==0.18.0\r\n",
      "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting torchaudio==2.3.0\r\n",
      "  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.19.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.15.0)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.9.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.0 (from torch==2.3.0)\r\n",
      "  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (4.67.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (2.32.5)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.3.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.18.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.18.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.18.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.18.0) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.18.0) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchtext==0.18.0) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (2025.8.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext==0.18.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtext==0.18.0) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchtext==0.18.0) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchtext==0.18.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchtext==0.18.0) (2024.2.0)\r\n",
      "Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchaudio, torchvision, torchtext\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cuml-cu12 25.2.1 requires cupy-cuda12x>=12.0.0, which is not installed.\r\n",
      "pylibcugraph-cu12 25.6.0 requires cupy-cuda12x>=12.0.0, which is not installed.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchtext-0.18.0 torchvision-0.18.0 triton-2.3.0\r\n",
      "Collecting en-core-web-sm==3.8.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\r\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\r\n",
      "order to load all the package's dependencies. You can do this by selecting the\r\n",
      "'Restart kernel' or 'Restart runtime' option.\r\n",
      "Collecting fr-core-news-sm==3.8.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: fr-core-news-sm\r\n",
      "Successfully installed fr-core-news-sm-3.8.0\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\r\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\r\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\r\n",
      "order to load all the package's dependencies. You can do this by selecting the\r\n",
      "'Restart kernel' or 'Restart runtime' option.\r\n"
     ]
    }
   ],
   "source": [
    "# 1. Gỡ cài đặt các bản lỗi\n",
    "!pip uninstall -y torch torchtext torchvision torchaudio\n",
    "\n",
    "# 2. Cài đặt phiên bản ổn định và TƯƠNG THÍCH (PyTorch 2.3 >= 1.13 -> Đạt yêu cầu)\n",
    "!pip install torch==2.3.0 torchtext==0.18.0 torchvision==0.18.0 torchaudio==2.3.0\n",
    "\n",
    "# 3. Tải dữ liệu ngôn ngữ cho Spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46118d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:00.294658Z",
     "iopub.status.busy": "2025-12-09T08:26:00.293948Z",
     "iopub.status.idle": "2025-12-09T08:26:07.151727Z",
     "shell.execute_reply": "2025-12-09T08:26:07.151115Z"
    },
    "papermill": {
     "duration": 6.898595,
     "end_time": "2025-12-09T08:26:07.153071",
     "exception": false,
     "start_time": "2025-12-09T08:26:00.254476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "en_tokenizer = get_tokenizer('spacy', 'en_core_web_sm')\n",
    "de_tokenizer = get_tokenizer('spacy', 'fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f1c5f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:07.232063Z",
     "iopub.status.busy": "2025-12-09T08:26:07.231455Z",
     "iopub.status.idle": "2025-12-09T08:26:07.236121Z",
     "shell.execute_reply": "2025-12-09T08:26:07.235316Z"
    },
    "papermill": {
     "duration": 0.04501,
     "end_time": "2025-12-09T08:26:07.237250",
     "exception": false,
     "start_time": "2025-12-09T08:26:07.192240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phiên bản Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "Phiên bản PyTorch: 2.3.0+cu121\n",
      "Phiên bản TorchText: 0.18.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "print(f\"Phiên bản Python: {sys.version}\")\n",
    "print(f\"Phiên bản PyTorch: {torch.__version__}\")\n",
    "print(f\"Phiên bản TorchText: {torchtext.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51eda2b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:07.314904Z",
     "iopub.status.busy": "2025-12-09T08:26:07.314629Z",
     "iopub.status.idle": "2025-12-09T08:26:07.336701Z",
     "shell.execute_reply": "2025-12-09T08:26:07.335840Z"
    },
    "papermill": {
     "duration": 0.062216,
     "end_time": "2025-12-09T08:26:07.337854",
     "exception": false,
     "start_time": "2025-12-09T08:26:07.275638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/usr/local/lib/python3.11/dist-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "import spacy\n",
    "import random\n",
    "import io\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f699ba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:07.415358Z",
     "iopub.status.busy": "2025-12-09T08:26:07.414526Z",
     "iopub.status.idle": "2025-12-09T08:26:07.418712Z",
     "shell.execute_reply": "2025-12-09T08:26:07.417956Z"
    },
    "papermill": {
     "duration": 0.043671,
     "end_time": "2025-12-09T08:26:07.419804",
     "exception": false,
     "start_time": "2025-12-09T08:26:07.376133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- CẤU HÌNH THIẾT BỊ ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63a1ab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:07.497945Z",
     "iopub.status.busy": "2025-12-09T08:26:07.497321Z",
     "iopub.status.idle": "2025-12-09T08:26:14.914248Z",
     "shell.execute_reply": "2025-12-09T08:26:14.913197Z"
    },
    "papermill": {
     "duration": 7.457754,
     "end_time": "2025-12-09T08:26:14.916194",
     "exception": false,
     "start_time": "2025-12-09T08:26:07.458440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Đang tải dữ liệu Multi30k (En-Fr) về Kaggle...\n",
      "Downloading train.en...\n",
      "Downloading train.fr...\n",
      "Downloading val.en...\n",
      "Downloading val.fr...\n",
      "Downloading test_2016_flickr.en...\n",
      "Downloading test_2016_flickr.fr...\n",
      "Downloading test_2017_flickr.en...\n",
      "Downloading test_2017_flickr.fr...\n",
      "Downloading test_2017_mscoco.en...\n",
      "Downloading test_2017_mscoco.fr...\n",
      "Downloading test_2018_flickr.en...\n",
      "Downloading test_2018_flickr.fr...\n",
      "\n",
      "--> Hoàn tất tải dữ liệu!\n",
      "Saved at: /kaggle/working/data\n",
      "Danh sách file: ['train.en', 'val.en', 'train.fr', 'test_2017_mscoco.fr', 'test_2018_flickr.en', 'val.fr', 'test_2016_flickr.fr', 'test_2017_flickr.en', 'test_2016_flickr.en', 'test_2017_mscoco.en', 'test_2018_flickr.fr', 'test_2017_flickr.fr']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Tạo thư mục chứa data\n",
    "data_dir = '/kaggle/working/data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "print(\"--> Đang tải dữ liệu Multi30k (En-Fr) về Kaggle...\")\n",
    "\n",
    "# Danh sách các URL file gốc (từ kho Multi30k chính thức)\n",
    "urls = {\n",
    "    # Train & Val\n",
    "    'train.en': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/train.en.gz',\n",
    "    'train.fr': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/train.fr.gz',\n",
    "    'val.en': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/val.en.gz',\n",
    "    'val.fr': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/val.fr.gz',\n",
    "    \n",
    "    # Test 2016 Flickr\n",
    "    'test_2016_flickr.en': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2016_flickr.en.gz',\n",
    "    'test_2016_flickr.fr': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2016_flickr.fr.gz',\n",
    "\n",
    "    # Test 2017 Flickr\n",
    "    'test_2017_flickr.en': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2017_flickr.en.gz',\n",
    "    'test_2017_flickr.fr': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2017_flickr.fr.gz',\n",
    "    \n",
    "    # Test 2017 MSCOCO\n",
    "    'test_2017_mscoco.en': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2017_mscoco.en.gz',\n",
    "    'test_2017_mscoco.fr': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2017_mscoco.fr.gz',\n",
    "\n",
    "    # Test 2018 Flickr (Lưu ý: Github thường đặt tên là test_2018.en.gz, ta sẽ đổi tên về đúng ý bạn)\n",
    "    'test_2018_flickr.en': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2018_flickr.en.gz',\n",
    "    'test_2018_flickr.fr': 'https://github.com/multi30k/dataset/raw/master/data/task1/raw/test_2018_flickr.fr.gz'\n",
    "}\n",
    "\n",
    "# Tải và giải nén\n",
    "for filename, url in urls.items():\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    gz_path = file_path + \".gz\"\n",
    "    \n",
    "    # Tải file .gz\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        # Dùng os.system gọi wget để tải\n",
    "        os.system(f\"wget -q -O {gz_path} {url}\")\n",
    "        \n",
    "        # Kiểm tra nếu tải lỗi (file rỗng hoặc không tồn tại)\n",
    "        if os.path.getsize(gz_path) < 100:\n",
    "             print(f\"⚠️ Error: Can't find {filename} on github.\")\n",
    "             os.remove(gz_path)\n",
    "             # Tạo file rỗng để code không bị crash, hoặc bạn có thể bỏ qua\n",
    "             with open(file_path, 'w') as f: f.write(\" \")\n",
    "        else:\n",
    "            # Giải nén\n",
    "            os.system(f\"gzip -d {gz_path}\")\n",
    "    else:\n",
    "        print(f\"File {filename} existed.\")\n",
    "\n",
    "print(\"\\n--> Hoàn tất tải dữ liệu!\")\n",
    "print(f\"Saved at: {data_dir}\")\n",
    "print(\"Danh sách file:\", os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4d5d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:14.996693Z",
     "iopub.status.busy": "2025-12-09T08:26:14.996461Z",
     "iopub.status.idle": "2025-12-09T08:26:19.243130Z",
     "shell.execute_reply": "2025-12-09T08:26:19.242317Z"
    },
    "papermill": {
     "duration": 4.287793,
     "end_time": "2025-12-09T08:26:19.244440",
     "exception": false,
     "start_time": "2025-12-09T08:26:14.956647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--> Đang đọc dữ liệu từ file vào List...\n",
      "Train: 29000 | Val: 1014\n",
      "Test Flickr 2016: 1000\n",
      "Test Flickr 2017: 1000\n",
      "Test Flickr 2018: 1071\n",
      "Test MSCOCO 2017: 461\n",
      "\n",
      "Building Vocabulary (from Training set only)...\n",
      "Vocab EN: 6191 | Vocab FR: 6555\n",
      "Data Prepared Successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Cấu hình thiết bị (Device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. CẤU HÌNH & TOKENIZER\n",
    "# ==========================================\n",
    "try:\n",
    "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spacy models...\")\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    os.system(\"python -m spacy download fr_core_news_sm\")\n",
    "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def tokenize_en(text): return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "def tokenize_fr(text): return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "# ==========================================\n",
    "# 2. HÀM ĐỌC DỮ LIỆU\n",
    "# ==========================================\n",
    "def load_data_to_list(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File {filepath} not found. Skipping or creating dummy.\")\n",
    "        return [] \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f]\n",
    "\n",
    "# Định nghĩa đường dẫn (Data Directory)\n",
    "data_dir = '/kaggle/working/data'\n",
    "\n",
    "# --- TRAIN & VAL PATHS ---\n",
    "train_en_path = os.path.join(data_dir, 'train.en')\n",
    "train_fr_path = os.path.join(data_dir, 'train.fr')\n",
    "val_en_path   = os.path.join(data_dir, 'val.en')\n",
    "val_fr_path   = os.path.join(data_dir, 'val.fr')\n",
    "\n",
    "# --- TEST PATHS (ĐẦY ĐỦ CÁC NĂM) ---\n",
    "# Flickr 2016\n",
    "test_2016_flickr_en_path = os.path.join(data_dir, 'test_2016_flickr.en')\n",
    "test_2016_flickr_fr_path = os.path.join(data_dir, 'test_2016_flickr.fr')\n",
    "\n",
    "# Flickr 2017\n",
    "test_2017_flickr_en_path = os.path.join(data_dir, 'test_2017_flickr.en')\n",
    "test_2017_flickr_fr_path = os.path.join(data_dir, 'test_2017_flickr.fr')\n",
    "\n",
    "# Flickr 2018\n",
    "test_2018_flickr_en_path = os.path.join(data_dir, 'test_2018_flickr.en')\n",
    "test_2018_flickr_fr_path = os.path.join(data_dir, 'test_2018_flickr.fr')\n",
    "\n",
    "# MSCOCO 2017\n",
    "test_2017_mscoco_en_path = os.path.join(data_dir, 'test_2017_mscoco.en')\n",
    "test_2017_mscoco_fr_path = os.path.join(data_dir, 'test_2017_mscoco.fr')\n",
    "\n",
    "print(\"--> Đang đọc dữ liệu từ file vào List...\")\n",
    "\n",
    "# --- LOAD DATA INTO LISTS ---\n",
    "# 1. Train & Val\n",
    "train_en_list = load_data_to_list(train_en_path)\n",
    "train_fr_list = load_data_to_list(train_fr_path)\n",
    "val_en_list   = load_data_to_list(val_en_path)\n",
    "val_fr_list   = load_data_to_list(val_fr_path)\n",
    "\n",
    "# 2. Test Lists (Quan trọng cho bước đánh giá sau này)\n",
    "test_2016_flickr_en_list = load_data_to_list(test_2016_flickr_en_path)\n",
    "test_2016_flickr_fr_list = load_data_to_list(test_2016_flickr_fr_path)\n",
    "\n",
    "test_2017_flickr_en_list = load_data_to_list(test_2017_flickr_en_path)\n",
    "test_2017_flickr_fr_list = load_data_to_list(test_2017_flickr_fr_path)\n",
    "\n",
    "test_2018_flickr_en_list = load_data_to_list(test_2018_flickr_en_path)\n",
    "test_2018_flickr_fr_list = load_data_to_list(test_2018_flickr_fr_path)\n",
    "\n",
    "test_2017_mscoco_en_list = load_data_to_list(test_2017_mscoco_en_path)\n",
    "test_2017_mscoco_fr_list = load_data_to_list(test_2017_mscoco_fr_path)\n",
    "\n",
    "# In thống kê\n",
    "print(f\"Train: {len(train_en_list)} | Val: {len(val_en_list)}\")\n",
    "print(f\"Test Flickr 2016: {len(test_2016_flickr_en_list)}\")\n",
    "print(f\"Test Flickr 2017: {len(test_2017_flickr_en_list)}\")\n",
    "print(f\"Test Flickr 2018: {len(test_2018_flickr_en_list)}\")\n",
    "print(f\"Test MSCOCO 2017: {len(test_2017_mscoco_en_list)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATASET & VOCAB\n",
    "# ==========================================\n",
    "class TranslationListDataset(Dataset):\n",
    "    def __init__(self, src_list, trg_list):\n",
    "        self.src_data = src_list\n",
    "        self.trg_data = trg_list\n",
    "    def __len__(self): return len(self.src_data)\n",
    "    def __getitem__(self, idx): return self.src_data[idx], self.trg_data[idx]\n",
    "\n",
    "# Tạo Dataset cho Train và Val\n",
    "train_ds = TranslationListDataset(train_en_list, train_fr_list)\n",
    "val_ds   = TranslationListDataset(val_en_list, val_fr_list)\n",
    "# Tạo Dataset mẫu cho Test (lấy Flickr 2016 làm đại diện để check loss nếu cần)\n",
    "test_ds  = TranslationListDataset(test_2016_flickr_en_list, test_2016_flickr_fr_list)\n",
    "\n",
    "SPECIAL_TOKENS = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "def build_vocab_from_list(text_list, tokenizer):\n",
    "    def yield_tokens(data_iter):\n",
    "        for text in data_iter: yield tokenizer(text)\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        yield_tokens(text_list), min_freq=2, specials=SPECIAL_TOKENS\n",
    "    )\n",
    "    vocab.set_default_index(UNK_IDX)\n",
    "    return vocab\n",
    "\n",
    "print(\"\\nBuilding Vocabulary (from Training set only)...\")\n",
    "vocab_en = build_vocab_from_list(train_en_list, tokenize_en)\n",
    "vocab_fr = build_vocab_from_list(train_fr_list, tokenize_fr)\n",
    "print(f\"Vocab EN: {len(vocab_en)} | Vocab FR: {len(vocab_fr)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. DATALOADER\n",
    "# ==========================================\n",
    "def text_pipeline(text, vocab, tokenizer):\n",
    "    return [SOS_IDX] + [vocab[token] for token in tokenizer(text)] + [EOS_IDX]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        src_batch.append(torch.tensor(text_pipeline(src_sample, vocab_en, tokenize_en)))\n",
    "        trg_batch.append(torch.tensor(text_pipeline(trg_sample, vocab_fr, tokenize_fr)))\n",
    "\n",
    "    src_lens = [len(x) for x in src_batch]\n",
    "    zipped = sorted(zip(src_batch, trg_batch, src_lens), key=lambda x: x[2], reverse=True)\n",
    "    src_batch, trg_batch, src_lens = zip(*zipped)\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, trg_batch, torch.tensor(src_lens)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_iterator = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_iterator = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_iterator  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(\"Data Prepared Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9477732f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:19.326799Z",
     "iopub.status.busy": "2025-12-09T08:26:19.326545Z",
     "iopub.status.idle": "2025-12-09T08:26:19.694860Z",
     "shell.execute_reply": "2025-12-09T08:26:19.694060Z"
    },
    "papermill": {
     "duration": 0.410303,
     "end_time": "2025-12-09T08:26:19.695956",
     "exception": false,
     "start_time": "2025-12-09T08:26:19.285653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Trainable parameters: 23,681,179\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# 1. ENCODER (BIDIRECTIONAL)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        # Bidirectional = True\n",
    "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        \n",
    "        # FC layers để nén 2 chiều hidden/cell của Encoder về 1 chiều cho Decoder\n",
    "        self.fc_hidden = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.fc_cell = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_len):\n",
    "        # src: [src len, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "\n",
    "        # Pack sequence\n",
    "        packed_embedded = pack_padded_sequence(embedded, src_len.to('cpu'), enforce_sorted=True)\n",
    "        packed_outputs, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        # Unpack sequence -> outputs: [src len, batch size, enc hid dim * 2]\n",
    "        outputs, _ = pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        # Xử lý Hidden state: Nối 2 hướng (Forward + Backward) và cho qua Linear\n",
    "        # hidden: [2, batch, enc_hid] -> [batch, enc_hid * 2] -> [batch, dec_hid]\n",
    "        hidden = torch.tanh(self.fc_hidden(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
    "        \n",
    "        # Xử lý Cell state tương tự (để khởi tạo cho Decoder LSTM)\n",
    "        cell = torch.tanh(self.fc_cell(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1)))\n",
    "        \n",
    "        return outputs, hidden, cell\n",
    "\n",
    "# 2. ATTENTION LAYER\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: [batch size, dec hid dim]\n",
    "        # encoder_outputs: [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        # Lặp lại hidden state src_len lần\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # [batch, src len, enc_hid*2]\n",
    "        \n",
    "        # Tính Energy\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2))) \n",
    "        \n",
    "        # Tính Attention score\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        # Trả về softmax (xác suất tập trung vào từ nào)\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "# 3. DECODER (WITH ATTENTION)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        # Input LSTM: Embedding + Context Vector (Enc_hid * 2)\n",
    "        self.rnn = nn.LSTM((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        # input: [batch size]\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input)) # [1, batch, emb]\n",
    "\n",
    "        # Tính Attention -> Context Vector\n",
    "        a = self.attention(hidden, encoder_outputs) # [batch, src len]\n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        weighted = torch.bmm(a, encoder_outputs) # [batch, 1, enc_hid*2]\n",
    "        weighted = weighted.permute(1, 0, 2) # [1, batch, enc_hid*2]\n",
    "        \n",
    "        # Đưa vào LSTM\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden.unsqueeze(0), cell.unsqueeze(0)))\n",
    "        \n",
    "        # Dự đoán\n",
    "        assert (output == hidden).all()\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), cell.squeeze(0)\n",
    "\n",
    "# 4. SEQ2SEQ\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_len)\n",
    "        \n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            \n",
    "            # Teacher Forcing\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1) \n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs\n",
    "\n",
    "# ==========================================\n",
    "# KHỞI TẠO MODEL\n",
    "# ==========================================\n",
    "INPUT_DIM = len(vocab_en)\n",
    "OUTPUT_DIM = len(vocab_fr)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512 # Encoder hidden\n",
    "DEC_HID_DIM = 512 # Decoder hidden\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param.data)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f\"Model initialized. Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "757e151f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:26:19.776568Z",
     "iopub.status.busy": "2025-12-09T08:26:19.776358Z",
     "iopub.status.idle": "2025-12-09T08:40:46.368740Z",
     "shell.execute_reply": "2025-12-09T08:40:46.367208Z"
    },
    "papermill": {
     "duration": 866.634323,
     "end_time": "2025-12-09T08:40:46.370057",
     "exception": false,
     "start_time": "2025-12-09T08:26:19.735734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Đang dọn dẹp file cũ và reset mô hình...\n",
      "\n",
      "Bắt đầu huấn luyện mới (20 Epochs)...\n",
      "Epoch: 01 | Time: 1m 36s\n",
      "\tTrain Loss: 4.029 | Train PPL:  56.185\n",
      "\t Val. Loss: 3.700 |  Val. PPL:  40.439\n",
      "\t--> Best Model Saved! (Loss giảm xuống 3.700)\n",
      "Epoch: 02 | Time: 1m 35s\n",
      "\tTrain Loss: 2.486 | Train PPL:  12.011\n",
      "\t Val. Loss: 3.089 |  Val. PPL:  21.945\n",
      "\t--> Best Model Saved! (Loss giảm xuống 3.089)\n",
      "Epoch: 03 | Time: 1m 35s\n",
      "\tTrain Loss: 1.828 | Train PPL:   6.224\n",
      "\t Val. Loss: 2.882 |  Val. PPL:  17.852\n",
      "\t--> Best Model Saved! (Loss giảm xuống 2.882)\n",
      "Epoch: 04 | Time: 1m 34s\n",
      "\tTrain Loss: 1.448 | Train PPL:   4.255\n",
      "\t Val. Loss: 2.732 |  Val. PPL:  15.367\n",
      "\t--> Best Model Saved! (Loss giảm xuống 2.732)\n",
      "Epoch: 05 | Time: 1m 35s\n",
      "\tTrain Loss: 1.178 | Train PPL:   3.247\n",
      "\t Val. Loss: 2.892 |  Val. PPL:  18.023\n",
      "\t--> Loss không giảm. Kiên nhẫn: 1/5\n",
      "Epoch: 06 | Time: 1m 34s\n",
      "\tTrain Loss: 0.985 | Train PPL:   2.678\n",
      "\t Val. Loss: 2.881 |  Val. PPL:  17.840\n",
      "\t--> Loss không giảm. Kiên nhẫn: 2/5\n",
      "Epoch: 07 | Time: 1m 34s\n",
      "\tTrain Loss: 0.845 | Train PPL:   2.329\n",
      "\t Val. Loss: 2.935 |  Val. PPL:  18.831\n",
      "\t--> Loss không giảm. Kiên nhẫn: 3/5\n",
      "Epoch: 08 | Time: 1m 34s\n",
      "\tTrain Loss: 0.742 | Train PPL:   2.100\n",
      "\t Val. Loss: 3.015 |  Val. PPL:  20.399\n",
      "\t--> Loss không giảm. Kiên nhẫn: 4/5\n",
      "Epoch: 09 | Time: 1m 34s\n",
      "\tTrain Loss: 0.651 | Train PPL:   1.917\n",
      "\t Val. Loss: 3.095 |  Val. PPL:  22.091\n",
      "\t--> Loss không giảm. Kiên nhẫn: 5/5\n",
      "\n",
      "[STOP] Dừng sớm do Loss không cải thiện nữa.\n",
      "\n",
      "Hoàn tất huấn luyện!\n",
      "File model tốt nhất đã lưu tại: /kaggle/working/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ==========================================\n",
    "# 6.3. HUẤN LUYỆN MÔ HÌNH (FRESH START - CHẠY LẠI TỪ ĐẦU)\n",
    "# ==========================================\n",
    "\n",
    "# Đường dẫn lưu Model trên Kaggle\n",
    "checkpoint_path = '/kaggle/working/checkpoint.pth'\n",
    "best_model_path = '/kaggle/working/best_model.pth'\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. DỌN DẸP & RESET MÔ HÌNH (QUAN TRỌNG)\n",
    "# ---------------------------------------------------------\n",
    "print(\"--> Đang dọn dẹp file cũ và reset mô hình...\")\n",
    "\n",
    "# Xóa file checkpoint cũ nếu có\n",
    "if os.path.exists(checkpoint_path):\n",
    "    os.remove(checkpoint_path)\n",
    "if os.path.exists(best_model_path):\n",
    "    os.remove(best_model_path)\n",
    "\n",
    "# Hàm khởi tạo lại trọng số (đưa model về trạng thái \"trắng tinh\")\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param.data)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "# Reset trọng số model\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Reset Optimizer (để xóa momentum cũ)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Định nghĩa Loss Function (bỏ qua padding token)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. CẤU HÌNH BIẾN QUẢN LÝ\n",
    "# ---------------------------------------------------------\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "start_epoch = 0\n",
    "best_valid_loss = float('inf')\n",
    "patience_counter = 0\n",
    "PATIENCE = 5  # Kiên nhẫn 5 epoch không giảm loss thì dừng\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. HÀM TRAIN & EVALUATE\n",
    "# ---------------------------------------------------------\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (src, trg, src_len) in enumerate(iterator):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Train: Teacher Forcing = 0.5 (Model học 50% từ đáp án đúng)\n",
    "        output = model(src, src_len, trg, teacher_forcing_ratio=0.5)\n",
    "        \n",
    "        # Reshape output để tính loss (bỏ qua token đầu <sos>)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradient để tránh bùng nổ gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg, src_len) in enumerate(iterator):\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            \n",
    "            # Eval: Teacher Forcing = 0.0 (Model phải tự đoán hoàn toàn)\n",
    "            output = model(src, src_len, trg, teacher_forcing_ratio=0.0)\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. VÒNG LẶP HUẤN LUYỆN CHÍNH (MAIN LOOP)\n",
    "# ---------------------------------------------------------\n",
    "print(f\"\\nBắt đầu huấn luyện mới ({N_EPOCHS} Epochs)...\")\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Chạy Train và Validate\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    # Tính thời gian\n",
    "    end_time = time.time()\n",
    "    epoch_mins = int((end_time - start_time) / 60)\n",
    "    epoch_secs = int((end_time - start_time) % 60)\n",
    "    \n",
    "    # Lưu lịch sử loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    # 1. Lưu Best Model (Quan trọng nhất)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"\\t--> Best Model Saved! (Loss giảm xuống {valid_loss:.3f})\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"\\t--> Loss không giảm. Kiên nhẫn: {patience_counter}/{PATIENCE}\")\n",
    "        \n",
    "    # 2. Lưu Checkpoint (để an toàn)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_valid_loss': best_valid_loss,\n",
    "        'train_losses': train_losses,\n",
    "        'valid_losses': valid_losses\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    # Early Stopping\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(\"\\n[STOP] Dừng sớm do Loss không cải thiện nữa.\")\n",
    "        break\n",
    "\n",
    "print(\"\\nHoàn tất huấn luyện!\")\n",
    "print(f\"File model tốt nhất đã lưu tại: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419044ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:40:46.529927Z",
     "iopub.status.busy": "2025-12-09T08:40:46.529506Z",
     "iopub.status.idle": "2025-12-09T08:40:46.799815Z",
     "shell.execute_reply": "2025-12-09T08:40:46.799066Z"
    },
    "papermill": {
     "duration": 0.312191,
     "end_time": "2025-12-09T08:40:46.800960",
     "exception": false,
     "start_time": "2025-12-09T08:40:46.488769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# VẼ BIỂU ĐỒ LOSS (YÊU CẦU MỤC 11)\n",
    "# ==========================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "130d6e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:40:46.882649Z",
     "iopub.status.busy": "2025-12-09T08:40:46.881968Z",
     "iopub.status.idle": "2025-12-09T08:40:47.033493Z",
     "shell.execute_reply": "2025-12-09T08:40:47.032526Z"
    },
    "papermill": {
     "duration": 0.193115,
     "end_time": "2025-12-09T08:40:47.034783",
     "exception": false,
     "start_time": "2025-12-09T08:40:46.841668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EN]: A dog runs in the park\n",
      "[FR]: Un chien court dans le parc\n",
      "\n",
      "[EN]: Two men are talking.\n",
      "[FR]: Ces hommes parlent .\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6.4. DỰ ĐOÁN (INFERENCE) - ATTENTION VERSION\n",
    "# ==========================================\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def translate(sentence: str):\n",
    "    # Đường dẫn file model\n",
    "    path_to_model = '/kaggle/working/best_model.pth'\n",
    "    \n",
    "    if not os.path.exists(path_to_model):\n",
    "        return \"Lỗi: Chưa có file best_model.pth. Hãy chạy Training trước!\"\n",
    "\n",
    "    # --- LOAD MODEL (Chỉ cần load 1 lần nếu chạy nhiều câu, nhưng để đây cho an toàn) ---\n",
    "    model.load_state_dict(torch.load(path_to_model, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # 1. Xử lý Input (Tokenize & Numericalize)\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = tokenize_en(sentence)\n",
    "        # Chuyển về chữ thường nếu cần (tùy vào cách build vocab)\n",
    "        tokens = [token.lower() for token in tokens] \n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Thêm <sos> và <eos>\n",
    "    tokens = ['<sos>'] + tokens + ['<eos>']\n",
    "    \n",
    "    # Convert sang index\n",
    "    src_indexes = [vocab_en[token] for token in tokens]\n",
    "    \n",
    "    # Tạo Tensor [src len, 1] (Batch size = 1)\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    src_len = torch.LongTensor([len(src_indexes)])\n",
    "\n",
    "    # 2. Encoder\n",
    "    with torch.no_grad():\n",
    "        # SỬA LỖI Ở ĐÂY: Unpack 3 giá trị thay vì 2\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
    "\n",
    "    # 3. Decoder (Greedy Decoding)\n",
    "    # Khởi tạo input đầu tiên là <sos>\n",
    "    trg_indexes = [vocab_fr['<sos>']]\n",
    "    max_len = 50 # Giới hạn độ dài câu dịch\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # SỬA LỖI Ở ĐÂY: Truyền thêm encoder_outputs vào Decoder\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell, encoder_outputs)\n",
    "\n",
    "        # Lấy token có xác suất cao nhất (Greedy)\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        # Gặp <eos> thì dừng\n",
    "        if pred_token == vocab_fr['<eos>']:\n",
    "            break\n",
    "\n",
    "    # 4. Convert ids -> text\n",
    "    trg_tokens = [vocab_fr.lookup_token(i) for i in trg_indexes]\n",
    "\n",
    "    # Loại bỏ <sos> ở đầu\n",
    "    result_tokens = trg_tokens[1:]\n",
    "    \n",
    "    # Loại bỏ <eos> ở cuối nếu có\n",
    "    if result_tokens and result_tokens[-1] == '<eos>':\n",
    "        result_tokens = result_tokens[:-1]\n",
    "\n",
    "    return \" \".join(result_tokens)\n",
    "\n",
    "# ==========================================\n",
    "# TEST THỬ NGHIỆM\n",
    "# ==========================================\n",
    "# Test 1: Câu đơn giản\n",
    "sample_1 = \"A dog runs in the park\" \n",
    "print(f\"\\n[EN]: {sample_1}\")\n",
    "print(f\"[FR]: {translate(sample_1)}\")\n",
    "\n",
    "# Test 2: Câu trong tập dữ liệu (Nếu có)\n",
    "sample_2 = \"Two men are talking.\"\n",
    "print(f\"\\n[EN]: {sample_2}\")\n",
    "print(f\"[FR]: {translate(sample_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "028de1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T08:40:47.119537Z",
     "iopub.status.busy": "2025-12-09T08:40:47.119234Z",
     "iopub.status.idle": "2025-12-09T08:41:35.001743Z",
     "shell.execute_reply": "2025-12-09T08:41:35.000824Z"
    },
    "papermill": {
     "duration": 47.925613,
     "end_time": "2025-12-09T08:41:35.003018",
     "exception": false,
     "start_time": "2025-12-09T08:40:47.077405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Đang tải model tốt nhất từ /kaggle/working/best_model.pth...\n",
      "\n",
      "==================================================\n",
      "BẮT ĐẦU ĐÁNH GIÁ (LIMIT = 2000 MẪU/BỘ)\n",
      "==================================================\n",
      "--> Đang đánh giá bộ: Flickr 2016 (Số mẫu: 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ...Đã xử lý 500 câu.\n",
      "    ...Đã xử lý 1000 câu.\n",
      "--> Kết quả Flickr 2016: 36.51 BLEU\n",
      "------------------------------\n",
      "--> Đang đánh giá bộ: Flickr 2017 (Số mẫu: 1000)\n",
      "    ...Đã xử lý 500 câu.\n",
      "    ...Đã xử lý 1000 câu.\n",
      "--> Kết quả Flickr 2017: 28.86 BLEU\n",
      "------------------------------\n",
      "--> Đang đánh giá bộ: Flickr 2018 (Số mẫu: 1071)\n",
      "    ...Đã xử lý 500 câu.\n",
      "    ...Đã xử lý 1000 câu.\n",
      "--> Kết quả Flickr 2018: 20.76 BLEU\n",
      "------------------------------\n",
      "--> Đang đánh giá bộ: MSCOCO 2017 (Số mẫu: 461)\n",
      "--> Kết quả MSCOCO 2017: 20.92 BLEU\n",
      "------------------------------\n",
      "\n",
      "==================================================\n",
      "TỔNG HỢP KẾT QUẢ BLEU SCORE\n",
      "==================================================\n",
      "Flickr 2016    : 36.51\n",
      "Flickr 2017    : 28.86\n",
      "Flickr 2018    : 20.76\n",
      "MSCOCO 2017    : 20.92\n",
      "------------------------------\n",
      "TRUNG BÌNH CHUNG : 26.76\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# ==========================================\n",
    "# 6.5. ĐÁNH GIÁ (EVALUATION & BLEU SCORE) - ĐA BỘ TEST\n",
    "# ==========================================\n",
    "\n",
    "# 1. Hàm dịch câu (CẬP NHẬT CHO ATTENTION MODEL)\n",
    "def translate_sentence(sentence, model, device, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    # 1. Xử lý Tokenize\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [tok.text.lower() for tok in spacy_en.tokenizer(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # 2. Thêm <sos>, <eos> và chuyển thành tensor\n",
    "    tokens = [vocab_en['<sos>']] + [vocab_en[token] for token in tokens] + [vocab_en['<eos>']]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(tokens).unsqueeze(1).to(device) # [src_len, 1]\n",
    "    src_len = torch.LongTensor([len(tokens)]) # Để ở CPU cho pack_padded_sequence\n",
    "\n",
    "    # 3. Encoder (SỬA ĐỔI QUAN TRỌNG)\n",
    "    with torch.no_grad():\n",
    "        # Attention Encoder trả về 3 giá trị\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
    "\n",
    "    # 4. Decoder Loop\n",
    "    trg_indexes = [vocab_fr['<sos>']]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Attention Decoder cần truyền thêm encoder_outputs\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell, encoder_outputs)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == vocab_fr['<eos>']:\n",
    "            break\n",
    "\n",
    "    # 5. Convert id -> Token text\n",
    "    trg_tokens = [vocab_fr.lookup_token(i) for i in trg_indexes]\n",
    "\n",
    "    # Trả về list token (bỏ <sos>)\n",
    "    return trg_tokens[1:]\n",
    "\n",
    "# 2. Hàm đánh giá một bộ dữ liệu\n",
    "def evaluate_single_set(model, dataset_name, src_list, trg_list, device, limit=2000):\n",
    "    \"\"\"\n",
    "    Tính BLEU score trung bình cho một tập dữ liệu\n",
    "    \"\"\"\n",
    "    bleu_scores = []\n",
    "    \n",
    "    # Giới hạn số mẫu để test nhanh hơn (nếu cần)\n",
    "    if limit:\n",
    "        src_eval = src_list[:limit]\n",
    "        trg_eval = trg_list[:limit]\n",
    "    else:\n",
    "        src_eval = src_list\n",
    "        trg_eval = trg_list\n",
    "\n",
    "    print(f\"--> Đang đánh giá bộ: {dataset_name} (Số mẫu: {len(src_eval)})\")\n",
    "\n",
    "    for i in range(len(src_eval)):\n",
    "        src = src_eval[i]\n",
    "        trg = trg_eval[i]\n",
    "\n",
    "        # A. Dự đoán (Candidate)\n",
    "        pred_tokens = translate_sentence(src, model, device)\n",
    "        \n",
    "        # Loại bỏ <eos> ở cuối nếu có\n",
    "        if pred_tokens and pred_tokens[-1] == '<eos>':\n",
    "            pred_tokens = pred_tokens[:-1]\n",
    "\n",
    "        # B. Thực tế (Reference)\n",
    "        # Lưu ý: Tokenize reference cũng cần lower để so sánh công bằng\n",
    "        trg_tokens = [tok.text.lower() for tok in spacy_fr.tokenizer(trg)]\n",
    "\n",
    "        # C. Tính BLEU\n",
    "        # sentence_bleu yêu cầu list of references (dạng lồng list) [[tok1, tok2...]]\n",
    "        score = sentence_bleu([trg_tokens], pred_tokens)\n",
    "        bleu_scores.append(score)\n",
    "        \n",
    "        # Log tiến độ\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(f\"    ...Đã xử lý {i + 1} câu.\")\n",
    "\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "    print(f\"--> Kết quả {dataset_name}: {avg_bleu*100:.2f} BLEU\")\n",
    "    return avg_bleu\n",
    "\n",
    "# 3. Hàm chạy toàn bộ quy trình (Main Wrapper)\n",
    "def run_full_evaluation(model, device):\n",
    "    # Load model tốt nhất\n",
    "    if not os.path.exists(best_model_path):\n",
    "        print(\"Lỗi: Không tìm thấy file model. Hãy train trước!\")\n",
    "        return\n",
    "\n",
    "    print(f\"--> Đang tải model tốt nhất từ {best_model_path}...\")\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    \n",
    "    # Định nghĩa các bộ test (Đảm bảo các biến này đã load ở cell Data)\n",
    "    test_datasets = {\n",
    "        \"Flickr 2016\": (test_2016_flickr_en_list, test_2016_flickr_fr_list),\n",
    "        \"Flickr 2017\": (test_2017_flickr_en_list, test_2017_flickr_fr_list),\n",
    "        \"Flickr 2018\": (test_2018_flickr_en_list, test_2018_flickr_fr_list),\n",
    "        \"MSCOCO 2017\": (test_2017_mscoco_en_list, test_2017_mscoco_fr_list)\n",
    "    }\n",
    "\n",
    "    all_scores = []\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"BẮT ĐẦU ĐÁNH GIÁ (LIMIT = 2000 MẪU/BỘ)\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    for name, (src_data, trg_data) in test_datasets.items():\n",
    "        # Kiểm tra nếu dữ liệu rỗng (tránh lỗi)\n",
    "        if len(src_data) == 0:\n",
    "            print(f\"Bỏ qua {name} vì không có dữ liệu.\")\n",
    "            continue\n",
    "            \n",
    "        score = evaluate_single_set(model, name, src_data, trg_data, device, limit=2000)\n",
    "        all_scores.append(score)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    final_avg_bleu = sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"TỔNG HỢP KẾT QUẢ BLEU SCORE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    for i, name in enumerate([n for n, d in test_datasets.items() if len(d[0]) > 0]):\n",
    "        print(f\"{name:<15}: {all_scores[i]*100:.2f}\")\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"TRUNG BÌNH CHUNG : {final_avg_bleu*100:.2f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# ==========================================\n",
    "# CHẠY ĐÁNH GIÁ\n",
    "# ==========================================\n",
    "run_full_evaluation(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c18707",
   "metadata": {
    "papermill": {
     "duration": 0.040399,
     "end_time": "2025-12-09T08:41:35.084336",
     "exception": false,
     "start_time": "2025-12-09T08:41:35.043937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1107.229747,
   "end_time": "2025-12-09T08:41:36.947091",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-09T08:23:09.717344",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
